{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n",
    "from keras.applications import VGG16,VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normal images\n",
      "541\n"
     ]
    }
   ],
   "source": [
    "!echo \"Number of Normal images\"\n",
    "!ls -l data/DATA_I_MADE/Images/Normal | egrep -c '^-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trolled images\n",
      "557\n"
     ]
    }
   ],
   "source": [
    "!echo \"Number of Trolled images\"\n",
    "!ls -l data/DATA_I_MADE/Images/Trolled | egrep -c '^-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 541, 557, 557)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normal_Images = ['data/DATA_I_MADE/Images/Normal/'+i for i in listdir('data/DATA_I_MADE/Images/Normal')]\n",
    "Trolled_Images = ['data/DATA_I_MADE/Images/Trolled/'+i for i in listdir('data/DATA_I_MADE/Images/Trolled')]\n",
    "Y_normal = [0]*len(Normal_Images)\n",
    "Y_trolled = [1]*len(Trolled_Images)\n",
    "len(Normal_Images),len(Y_normal),len(Trolled_Images),len(Y_trolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098, 1098)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images = Normal_Images+Trolled_Images\n",
    "labels = Y_normal+Y_trolled\n",
    "len(Images),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(Images, labels, test_size=0.1, random_state=42, stratify=labels)\n",
    "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.11, random_state=42, stratify=trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_pkl(file_location,item):\n",
    "    with open(file_location, 'wb') as fp:\n",
    "        pickle.dump(item, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/trainX.pickle',trainX)\n",
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/testX.pickle',testX)\n",
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/valX.pickle',valX)\n",
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/trainY.pickle',trainY)\n",
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/testY.pickle',testY)\n",
    "dump_to_pkl('data/DATA_I_MADE/train_test_val_split/valY.pickle',valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pkl(file_location):\n",
    "    with open (file_location, 'rb') as fp:\n",
    "        itemlist = pickle.load(fp)\n",
    "    return itemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = read_from_pkl('data/DATA_I_MADE/train_test_val_split/trainX.pickle')\n",
    "testX = read_from_pkl('data/DATA_I_MADE/train_test_val_split/testX.pickle')\n",
    "valX = read_from_pkl('data/DATA_I_MADE/train_test_val_split/valX.pickle')\n",
    "trainY = read_from_pkl('data/DATA_I_MADE/train_test_val_split/trainY.pickle')\n",
    "testY = read_from_pkl('data/DATA_I_MADE/train_test_val_split/testY.pickle')\n",
    "valY = read_from_pkl('data/DATA_I_MADE/train_test_val_split/valY.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879, 879, 110, 110, 109, 109)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX),len(trainY),len(testX),len(testY),len(valX),len(valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess(image_name):\n",
    "    img = image.load_img(image_name, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = [read_and_preprocess(i) for i in tqdm(trainX)]\n",
    "testX = [read_and_preprocess(i) for i in tqdm(testX)]\n",
    "valX = [read_and_preprocess(i) for i in tqdm(valX)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitkul/anaconda3/envs/nii_project/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=base_model.input, output=base_model.get_layer('fc2').output)\n",
    "fc2_features = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nii_project)",
   "language": "python",
   "name": "nii_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
